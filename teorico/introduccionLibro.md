# Fundamentos del Dise√±o de Computadores

Mientras que las mejoras tecnol√≥gicas han sido bastante
constantes, el progreso en la obtenci√≥n de mejores arquitecturas ha sido mucho menos consistente.

Durante los veinte √∫ltimos a√±os, los dise√±adores de computadores han dependido enormemente de la tecnolog√≠a de circuitos integrados. El crecimiento del
rendimiento durante este per√≠odo varia del 18 al 35 por 100 por a√±o, dependiendo de la clase de computador.

# Definiciones de Rendimiento

Para familiarizar al lector con la terminolog√≠a y conceptos de este libro, este
cap√≠tulo introduce algunos t√©rminos e ideas clave. Ejemplos de las ideas mencionadas aqu√≠ aparecen a lo largo del libro, y algunas de ellas -segmentaci√≥n
(pipelining), jerarqu√≠a de memoria, rendimiento de la CPU y medida de costes- son el n√∫cleo de cap√≠tulos completos. Comencemos con definiciones de
rendimiento relativo.

Cuando se dice que un computador es m√°s r√°pido que otro, ¬øqu√© queremos significar? El usuario del' computador puede decir que un computador es
m√°s r√°pido cuando ejecuta un programa en menos tiempo, mientras que el
director de un centro de c√°lculo puede decir que un computador es m√°s r√°pido cuando completa m√°s tareas en una hora. El usuario del computador est√° interesado en reducir el tiempo de respuesta -el tiempo transcunido entre el
comienzo y el final de un evento- denominado tambi√©n `tiempo de ejecuci√≥n`
o `latencia`. El director del centro de c√°lculo est√° interesado en incrementar la
`productividad (throughput)` -la cantidad total de trabajo realizado en un
tiempo determinado- a veces denominado `ancho de banda`. Normalmente,
los t√©rminos `¬´tiempo de respuesta¬ª, ¬´tiempo de ejecuci√≥n¬ª y ¬´productividad¬ª`
se utilizan cuando se est√° desarrollando una tarea de c√°lculo completa. Los
t√©rminos de `latencia y ¬´ancho de banda¬ª` casi siempre se eligen cuando se habla de un `sistema de memoria`.

### EJEMPLO

¬øLas siguientes mejoras en rendimiento incrementan la productividad, hacen disminuir el tiempo de respuesta, o ambas cosas?

1. Ciclo de reloj m√°s r√°pido. 
 
2. M√∫ltiples procesadores para tareas separadas (tratamiento del sistema de reservas de una compa√±√≠a a√©rea, para un pa√≠s, por ejemplo).

3. Procesamiento paralelo de problemas cient√≠ficos.

`RESPUESTA:` La disminuci√≥n del tiempo de respuesta, habitualmente, mejora la productividad. Por consiguiente, 1 y 3 mejoran el tiempo de respuesta y la productividad. En 2, ninguna tarea funciona m√°s r√°pida, por tanto, s√≥lo incrementa
la productividad. 

### RENDIMINETO

Cuando se comparan alternativas de dise√±o, con frecuencia, queremos relacionar el rendimiento de dos m√°quinas diferentes, por ejemplo X e Y. La frase ¬´X es m√°s r√°pida que Y¬ª se utiliza aqu√≠ para significar que el tiempo de
respuesta o tiempo de ejecuci√≥n es inferior en X que en Y para una tarea dada.
En particular, ¬´X es n por 100 m√°s r√°pido que Y¬ª significa 

![alt text](imgLibro/rendimiento1.png)

Como el tiempo de ejecuci√≥n es el rec√≠proco del rendimiento, se mantiene la
siguiente relaci√≥n: 

![alt text](imgLibro/rendimiento2.png)


Algunas personas consideran un incremento en el rendimiento, n, como la diferencia entre el rendimiento de la m√°quina m√°s r√°pida y la m√°s lenta, dividido por el rendimiento de la m√°quina m√°s lenta. Esta definici√≥n de n es exactamente equivalente a nuestra primera definici√≥n, como podemos ver: 

![alt text](imgLibro/rendimiento3.png)

---

### Rendimiento, tiempo de ejecuci√≥n y segmentaci√≥n (pipelining)

El **rendimiento** y el **tiempo de ejecuci√≥n** son inversos entre s√≠:  
- Si **aumentamos el rendimiento**, autom√°ticamente **disminuye el tiempo de ejecuci√≥n**.  
- Para evitar confusiones, solemos hablar de **‚Äúmejorar el rendimiento‚Äù** o **‚Äúmejorar el tiempo de ejecuci√≥n‚Äù** (ambas expresiones significan lo mismo: m√°s r√°pido).

---

### Productividad vs Latencia

En el dise√±o de computadores entran en juego dos conceptos diferentes:  
- **Productividad (throughput):** cu√°ntas instrucciones o tareas completas puede ejecutar la m√°quina en un per√≠odo de tiempo.  
- **Latencia:** cu√°nto tarda en completarse una sola instrucci√≥n o tarea.  

Estos dos valores no siempre cambian en la misma direcci√≥n.

---

### Segmentaci√≥n de instrucciones (pipelining)

La **segmentaci√≥n** divide la ejecuci√≥n de una instrucci√≥n en varias etapas, 
permitiendo **solapar la ejecuci√≥n de m√∫ltiples instrucciones** al mismo tiempo.  

Un ejemplo cl√°sico es la **l√≠nea de ensamblaje de autos**:  
- Fabricar un coche entero puede llevar 8 horas.  
- Si dividimos el proceso en 8 etapas de 1 hora, entonces **cada hora sale un coche terminado**, porque hay 8 en construcci√≥n simult√°nea.  

üëâ En este caso:  
- La **latencia** para fabricar un coche **sigue siendo 8 horas**.  
- La **productividad aumenta**: ahora se completa 1 coche por hora, no 1 cada 8 horas.

---

### En los computadores

- El pipelining **no reduce la latencia de una instrucci√≥n individual**.  
- Pero s√≠ **incrementa el n√∫mero de instrucciones completadas por unidad de tiempo** (mayor rendimiento).  
- Cada etapa del cauce introduce un peque√±o **gasto adicional (overhead)**, lo que puede aumentar ligeramente la latencia total.

---

### Resumen

- **Mejorar rendimiento = reducir tiempo de ejecuci√≥n.**  
- **Latencia ‚â† productividad.**  
- El **pipelining** no acelera instrucciones individuales, pero **permite terminar m√°s instrucciones por segundo** gracias al paralelismo.
---


# Principios Cuantitativos del Dise√±o de Computadores

## 1. Acelerar el caso com√∫n
El principio m√°s importante del dise√±o de computadores es **optimizar el caso frecuente**.  
- Cuando dise√±amos, conviene favorecer lo que ocurre con m√°s frecuencia en lugar de lo raro.  
- Mejorar lo que pasa seguido tiene m√°s impacto en el rendimiento global.  
- Muchas veces, lo com√∫n es m√°s **simple** y se puede **optimizar mejor**.

**Ejemplo:**  
Al sumar dos n√∫meros en la CPU puede ocurrir un *desbordamiento* (overflow), pero eso es poco com√∫n.  
- En lugar de dise√±ar la CPU pensando en ese caso raro, conviene optimizar la suma normal (que ocurre siempre).  
- As√≠, el rendimiento global mejora, porque el caso com√∫n se hace m√°s r√°pido.

---

## 2. Ley de Amdahl
La **Ley de Amdahl** nos dice cu√°nto puede mejorar el rendimiento de un sistema cuando optimizamos solo una parte de √©l.  

- **Idea central:**  
  * La mejora global est√° limitada por la fracci√≥n de tiempo en que podemos aplicar la mejora.  
  * Si la mejora aplica solo a un 40% del tiempo de ejecuci√≥n, no podemos acelerar el programa m√°s all√° de cierto l√≠mite.

**Definici√≥n de aceleraci√≥n (speedup):**

$$
\text{Aceleraci√≥n} = \frac{\text{Tiempo ejecuci√≥n sin mejora}}{\text{Tiempo ejecuci√≥n con mejora}}
$$


---

### Ejemplo: Viaje de Nevada a California
- Se tarda **20 horas** en cruzar las monta√±as (tiempo fijo).  
- Luego hay **200 millas** que se pueden recorrer con distintos medios de transporte.  

Opciones para la segunda parte del viaje:  
1. A pie ‚Üí 4 mph ‚Üí 50 h.  
2. Bicicleta ‚Üí 10 mph ‚Üí 20 h.  
3. Auto Hyundai ‚Üí 50 mph ‚Üí 4 h.  
4. Ferrari ‚Üí 120 mph ‚Üí 1,67 h.  
5. Veh√≠culo oruga ‚Üí 600 mph ‚Üí 0,33 h.  

**Conclusi√≥n:**  
Aunque mejores mucho la segunda parte (usar un Ferrari o un veh√≠culo oruga), el tiempo total sigue dominado por las **20 horas de las monta√±as**.  
La aceleraci√≥n global siempre est√° limitada por la parte que **no mejora**.

---

### F√≥rmula de Amdahl
Si una fracci√≥n del programa es mejorada, la aceleraci√≥n global es:

$$
\text{Aceleraci√≥n global} = \frac{1}{(1 - F_{mejorada}) + \frac{F_{mejorada}}{A_{mejorada}}}
$$

Donde:  
- \(F_{mejorada}\) = fracci√≥n de tiempo mejorable.  
- \(A_{mejorada}\) = aceleraci√≥n en la parte mejorada.

**Ejemplo num√©rico:**  
- La mejora se usa en el 40% del tiempo (\(F_{mejorada} = 0.4\)).  
- La parte mejorada es 10 veces m√°s r√°pida (\(A_{mejorada} = 10\)).  

$$
\text{Aceleraci√≥n global} = \frac{1}{0.6 + \frac{0.4}{10}} = \frac{1}{0.64} \approx 1.56
$$

---

## 3. Coste/Rendimiento
No siempre conviene mejorar una parte si el **coste** supera la ganancia de rendimiento.  

**Ejemplo:**  
- Si mejorar la CPU √ó5 cuesta m√°s del doble del precio total del sistema, puede que la inversi√≥n no valga la pena.  
- Lo importante es evaluar la **relaci√≥n coste/rendimiento**.

---

## 4. Localidad de Referencia
Otro principio b√°sico en el dise√±o de computadores es la **localidad**:  
Los programas tienden a **reutilizar datos e instrucciones recientes**.  

Tipos de localidad:  
- **Temporal:** lo usado recientemente se volver√° a usar pronto.  
- **Espacial:** lo que est√° cerca en memoria tiende a usarse en conjunto.  

**Ejemplo:**  
Un programa puede pasar el 90% de su tiempo ejecutando solo el 10% de sus instrucciones.  
Esto permite predecir y optimizar qu√© datos o instrucciones se van a usar en el futuro.

---

## 5. Gr√°fico de referencias
Un estudio de programas reales (GCC, Spice, TeX) mostr√≥ que:  
- El **80‚Äì90% de todas las referencias** se concentran en **menos del 10% de las instrucciones**.  
- Esto confirma que los programas usan **un peque√±o conjunto de instrucciones muchas veces** (gran localidad).

![alt text](imgLibro/localidad.png)

